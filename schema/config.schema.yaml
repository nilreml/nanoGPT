$defs:
  AdamWConfig:
    properties:
      beta1:
        exclusiveMaximum: 1.0
        exclusiveMinimum: 0.0
        title: Beta1
        type: number
      beta2:
        exclusiveMaximum: 1.0
        exclusiveMinimum: 0.0
        title: Beta2
        type: number
      name:
        const: adam_w
        enum:
        - adam_w
        title: Name
        type: string
    required:
    - name
    - beta1
    - beta2
    title: AdamWConfig
    type: object
  DType:
    enum:
    - float16
    - float32
    - bfloat16
    title: DType
    type: string
  GPTConfig:
    description: Pydantic model containing GPT LLM configuration.
    properties:
      bias:
        title: Bias
        type: boolean
      dim_model:
        title: Dim Model
        type: integer
      dropout:
        description: Dropout probability, 0.0 to disable
        exclusiveMaximum: 1.0
        minimum: 0.0
        title: Dropout
        type: number
      num_heads:
        title: Num Heads
        type: integer
      num_layers:
        title: Num Layers
        type: integer
      seq_len:
        title: Seq Len
        type: integer
      vocab_size:
        title: Vocab Size
        type: integer
    required:
    - seq_len
    - dim_model
    - num_heads
    - num_layers
    - vocab_size
    - bias
    - dropout
    title: GPTConfig
    type: object
  LearningRateConfig:
    properties:
      decay_schedule:
        enum:
        - none
        - cosine_decay
        title: Decay Schedule
        type: string
      max:
        exclusiveMinimum: 0.0
        title: Max
        type: number
      min:
        exclusiveMinimum: 0.0
        title: Min
        type: number
      warmup_iters:
        minimum: 0
        title: Warmup Iters
        type: integer
      warmup_schedule:
        const: linear
        enum:
        - linear
        title: Warmup Schedule
        type: string
    required:
    - max
    - min
    - warmup_schedule
    - warmup_iters
    - decay_schedule
    title: LearningRateConfig
    type: object
  OptimizationConfig:
    properties:
      grad_clip:
        description: Gradient clipping value, 0 to disable
        minimum: 0.0
        title: Grad Clip
        type: number
      learning_rate:
        $ref: '#/$defs/LearningRateConfig'
      max_iters:
        description: Maximum number of training iterations
        exclusiveMinimum: 0
        title: Max Iters
        type: integer
      optimizer:
        $ref: '#/$defs/AdamWConfig'
      weight_decay:
        description: Weight decay value, 0 to disable
        minimum: 0.0
        title: Weight Decay
        type: number
    required:
    - max_iters
    - grad_clip
    - weight_decay
    - learning_rate
    - optimizer
    title: OptimizationConfig
    type: object
  TrainConfig:
    description: Pydantic model containing training configuration.
    properties:
      batch_size:
        exclusiveMinimum: 0
        title: Batch Size
        type: integer
      compile:
        title: Compile
        type: boolean
      dataset:
        format: path
        title: Dataset
        type: string
      device_type:
        enum:
        - cpu
        - cuda
        title: Device Type
        type: string
      dtype:
        $ref: '#/$defs/DType'
      init_from:
        default: scratch
        title: Init From
        type: string
      optimization:
        $ref: '#/$defs/OptimizationConfig'
      out_dir:
        default: out
        title: Out Dir
        type: string
      seed_offset:
        minimum: 0
        title: Seed Offset
        type: integer
    required:
    - dataset
    - batch_size
    - optimization
    - seed_offset
    - dtype
    - compile
    - device_type
    title: TrainConfig
    type: object
description: Pydantic model containing gpt model and training configuration.
properties:
  model:
    $ref: '#/$defs/GPTConfig'
  name:
    title: Name
    type: string
  train:
    $ref: '#/$defs/TrainConfig'
required:
- name
- model
- train
title: RootConfig
type: object
